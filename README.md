# Fraud analytics with DBT

<p align="center">
  <a href="#about">About</a> â€¢
  <a href="#architecture">Architecture</a> â€¢
  <a href="#project-structure">Project Structure</a> â€¢
  <a href="#docker-way-to-quick-start">Quick Start</a>
</p>

 > [!NOTE]
 >
 > This repository is a **student project** for the 2025 HSE/MTS MLOps course. It is based on the Kaggle dataset [customer-support-ticket-dataset](https://www.kaggle.com/datasets/suraj520/customer-support-ticket-dataset/data).

## About

This project is an end-to-end ticket triage service for customer support. Tickets are streamed via Kafka, scored in real time by an ML inference service (CatBoost priority prediction), stored in ClickHouse and visualized in a Streamlit analytics dashboard with dbt marts refreshed on a schedule by Airflow.


## Architecture

**Components:**

- **ui (Streamlit UI)**
  - Accepts a CSV file with support tickets (one row = one ticket)
  - Publishes tickets to Kafka topic `tickets`
  - Provides two pages:
    - **Home**: upload + send
    - **Analytics**: charts and tables built from dbt marts

- **scorer (ML Service)**
  - Loads a pre-trained **CatBoost** model
  - Runs preprocessing
  - Consumes tickets from Kafka topic `tickets`
  - Publishes scored results to Kafka topic `tickets_scored`

- **clickhouse**
  - Kafka-engine table consumes messages from topic `tickets_scored`
  - Materialized view writes data into `db_tickets.tickets` MergeTree for analytics
  - Table schema is analytics-optimized (compression codecs, tuned partitioning/sorting)

- **dbt**
  - Builds `stg_tickets` staging model from `db_tickets.tickets`
  - Produces analytical models for the dashboard (distributions, top products, recent open tickets)
  - Runs schema validations and data-quality tests

- **airflow**
  - Schedules dbt runs (keeps marts up-to-date for analytics)

- **Kafka Infrastructure**
  - **Kafka** (KRaft mode)
  - **kafka-setup**: auto-creates topics `tickets` and `tickets_scored`

## Project Structure

```text
ticket-triage-service/
â”œâ”€â”€ clickhouse/
â”‚   â””â”€â”€ init/
â”‚       â””â”€â”€ create_schema.sql
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ airflow/
â”‚   â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”‚   â””â”€â”€ dbt_marts.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ dbt/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ marts/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mart_age_type_priority.sql
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mart_gender_priority.sql
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mart_priority_distribution.sql
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mart_recent_open_tickets.sql
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mart_status_distribution.sql
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mart_ticket_channel_distribution.sql
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mart_ticket_type_distribution.sql
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ mart_top_products_critical.sql
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ schema.yml
â”‚   â”‚   â”‚   â”œâ”€â”€ sources/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ source.yml
â”‚   â”‚   â”‚   â””â”€â”€ staging/
â”‚   â”‚   â”‚       â”œâ”€â”€ stg_tickets.sql
â”‚   â”‚   â”‚       â””â”€â”€ stg_tickets.yml
â”‚   â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ packages.yml
â”‚   â”‚   â”œâ”€â”€ profiles.yml
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ scorer/
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ ui/
â”‚       â”œâ”€â”€ .streamlit/
â”‚       â”‚   â””â”€â”€ config.toml
â”‚       â”œâ”€â”€ pages/
â”‚       â”‚   â”œâ”€â”€ analytics.py
â”‚       â”‚   â””â”€â”€ home.py
â”‚       â”œâ”€â”€ app.py
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ requirements.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ logger/
â”‚   â”‚   â”œâ”€â”€ logger_config.json
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ model.cbm
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ inference.py
â”‚       â”œâ”€â”€ io_utils.py
â”‚       â””â”€â”€ preprocessing.py
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```


<h2 id="docker-way-to-quick-start">ğŸ³ Docker-way to Quick Start</h2>

### Prerequisites
- Docker â‰¥ 20.10
- Docker Compose â‰¥ v2
- Disk space ~ 4 GB

### Build & Run

```bash
docker compose up -d --build
```

### Open interfaces

- Streamlit UI â†’ [http://localhost:8501](http://localhost:8501)


### Workflow

1. **Upload a CSV file** with support tickets through Streamlit UI.

2. **Click Send** to stream tickets.

3. **Go to Analytics** to explore triage results:
   - Total processed tickets
   - Priority / status / type / channel distributions
   - Top products by critical rate
   - Recent open tickets

### Logs

Each service writes logs. You can view them with:
```bash
docker compose logs <service_name> # Example: scorer, ui, dbt...
```
